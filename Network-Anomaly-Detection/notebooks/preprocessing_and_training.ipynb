{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178153b-c5e5-4b59-8226-bbfd59d7957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 Columns after renaming: Index(['pkSeqID', 'proto', 'saddr', 'sport', 'daddr', 'dport', 'seq', 'stddev',\n",
      "       'N_IN_Conn_P_SrcIP', 'min', 'state_number', 'mean', 'N_IN_Conn_P_DstIP',\n",
      "       'drate', 'srate', 'max', 'label', 'type', 'subcategory'],\n",
      "      dtype='object')\n",
      "Dataset 2 Columns after renaming: Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
      "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
      "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'type', 'label'],\n",
      "      dtype='object')\n",
      "Dataset 3 Columns after renaming: Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'proto', 'service',\n",
      "       'duration', 'src_bytes', 'dst_bytes', 'conn_state', 'missed_bytes',\n",
      "       'src_pkts', 'src_ip_bytes', 'dst_pkts', 'dst_ip_bytes', 'dns_query',\n",
      "       'dns_qclass', 'dns_qtype', 'dns_rcode', 'dns_AA', 'dns_RD', 'dns_RA',\n",
      "       'dns_rejected', 'ssl_version', 'ssl_cipher', 'ssl_resumed',\n",
      "       'ssl_established', 'ssl_subject', 'ssl_issuer', 'http_trans_depth',\n",
      "       'http_method', 'http_uri', 'http_version', 'http_request_body_len',\n",
      "       'http_response_body_len', 'http_status_code', 'http_user_agent',\n",
      "       'http_orig_mime_types', 'http_resp_mime_types', 'weird_name',\n",
      "       'weird_addl', 'weird_notice', 'label', 'type'],\n",
      "      dtype='object')\n",
      "Dataset 1 'label' column values:\n",
      " label\n",
      "1    2934447\n",
      "0        370\n",
      "Name: count, dtype: int64\n",
      "Dataset 2 'label' column values:\n",
      " label\n",
      "1    119341\n",
      "0     56000\n",
      "Name: count, dtype: int64\n",
      "Dataset 3 'label' column values:\n",
      " label\n",
      "1    161043\n",
      "0     50000\n",
      "Name: count, dtype: int64\n",
      "Combined DataFrame Columns: Index(['pkSeqID', 'proto', 'saddr', 'sport', 'daddr', 'dport', 'seq', 'stddev',\n",
      "       'N_IN_Conn_P_SrcIP', 'min',\n",
      "       ...\n",
      "       'http_version', 'http_request_body_len', 'http_response_body_len',\n",
      "       'http_status_code', 'http_user_agent', 'http_orig_mime_types',\n",
      "       'http_resp_mime_types', 'weird_name', 'weird_addl', 'weird_notice'],\n",
      "      dtype='object', length=101)\n",
      "Combined DataFrame 'label' column values:\n",
      " label\n",
      "1    3214831\n",
      "0     106370\n",
      "Name: count, dtype: int64\n",
      "Combined DataFrame shape: (3321201, 101)\n",
      "Number of missing values per column:\n",
      " pkSeqID                  386384\n",
      "proto                         0\n",
      "saddr                    386384\n",
      "sport                    386384\n",
      "daddr                    386384\n",
      "                         ...   \n",
      "http_orig_mime_types    3110158\n",
      "http_resp_mime_types    3110158\n",
      "weird_name              3110158\n",
      "weird_addl              3110158\n",
      "weird_notice            3110158\n",
      "Length: 101, dtype: int64\n",
      "Data types of columns:\n",
      " pkSeqID                 float64\n",
      "proto                    object\n",
      "saddr                    object\n",
      "sport                    object\n",
      "daddr                    object\n",
      "                         ...   \n",
      "http_orig_mime_types     object\n",
      "http_resp_mime_types     object\n",
      "weird_name               object\n",
      "weird_addl               object\n",
      "weird_notice             object\n",
      "Length: 101, dtype: object\n",
      "Combined DataFrame Head:\n",
      "      pkSeqID proto            saddr  sport          daddr dport       seq  \\\n",
      "0  3142762.0   udp  192.168.100.150   6551  192.168.100.3    80  251984.0   \n",
      "1  2432264.0   tcp  192.168.100.150   5532  192.168.100.3    80  256724.0   \n",
      "2  1976315.0   tcp  192.168.100.147  27165  192.168.100.3    80   62921.0   \n",
      "3  1240757.0   udp  192.168.100.150  48719  192.168.100.3    80   99168.0   \n",
      "4  3257991.0   udp  192.168.100.147  22461  192.168.100.3    80  105063.0   \n",
      "\n",
      "     stddev  N_IN_Conn_P_SrcIP       min  ...  http_version  \\\n",
      "0  1.900363              100.0  0.000000  ...           NaN   \n",
      "1  0.078003               38.0  3.856930  ...           NaN   \n",
      "2  0.268666              100.0  2.974100  ...           NaN   \n",
      "3  1.823185               63.0  0.000000  ...           NaN   \n",
      "4  0.822418              100.0  2.979995  ...           NaN   \n",
      "\n",
      "   http_request_body_len  http_response_body_len  http_status_code  \\\n",
      "0                    NaN                     NaN               NaN   \n",
      "1                    NaN                     NaN               NaN   \n",
      "2                    NaN                     NaN               NaN   \n",
      "3                    NaN                     NaN               NaN   \n",
      "4                    NaN                     NaN               NaN   \n",
      "\n",
      "   http_user_agent  http_orig_mime_types  http_resp_mime_types weird_name  \\\n",
      "0              NaN                   NaN                   NaN        NaN   \n",
      "1              NaN                   NaN                   NaN        NaN   \n",
      "2              NaN                   NaN                   NaN        NaN   \n",
      "3              NaN                   NaN                   NaN        NaN   \n",
      "4              NaN                   NaN                   NaN        NaN   \n",
      "\n",
      "  weird_addl  weird_notice  \n",
      "0        NaN           NaN  \n",
      "1        NaN           NaN  \n",
      "2        NaN           NaN  \n",
      "3        NaN           NaN  \n",
      "4        NaN           NaN  \n",
      "\n",
      "[5 rows x 101 columns]\n",
      "Columns after handling missing values:\n",
      " Index(['proto', 'seq', 'stddev', 'N_IN_Conn_P_SrcIP', 'min', 'state_number',\n",
      "       'mean', 'N_IN_Conn_P_DstIP', 'drate', 'srate', 'max', 'label', 'type',\n",
      "       'subcategory', 'id', 'dur', 'service', 'state', 'spkts', 'dpkts',\n",
      "       'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss',\n",
      "       'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb',\n",
      "       'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'src_ip', 'src_port', 'dst_ip',\n",
      "       'dst_port', 'duration', 'src_bytes', 'dst_bytes', 'conn_state',\n",
      "       'missed_bytes', 'src_pkts', 'src_ip_bytes', 'dst_pkts', 'dst_ip_bytes',\n",
      "       'dns_query', 'dns_qclass', 'dns_qtype', 'dns_rcode', 'dns_AA', 'dns_RD',\n",
      "       'dns_RA', 'dns_rejected', 'ssl_version', 'ssl_cipher', 'ssl_resumed',\n",
      "       'ssl_established', 'ssl_subject', 'ssl_issuer', 'http_trans_depth',\n",
      "       'http_method', 'http_uri', 'http_version', 'http_request_body_len',\n",
      "       'http_response_body_len', 'http_status_code', 'http_user_agent',\n",
      "       'http_orig_mime_types', 'http_resp_mime_types', 'weird_name',\n",
      "       'weird_addl', 'weird_notice'],\n",
      "      dtype='object')\n",
      "Before encoding: (3321201, 96)\n",
      "Categorical columns to encode: Index(['proto', 'type', 'subcategory', 'service', 'state', 'src_ip', 'dst_ip',\n",
      "       'conn_state', 'dns_query', 'dns_AA', 'dns_RD', 'dns_RA', 'dns_rejected',\n",
      "       'ssl_version', 'ssl_cipher', 'ssl_resumed', 'ssl_established',\n",
      "       'ssl_subject', 'ssl_issuer', 'http_trans_depth', 'http_method',\n",
      "       'http_uri', 'http_version', 'http_user_agent', 'http_orig_mime_types',\n",
      "       'http_resp_mime_types', 'weird_name', 'weird_addl', 'weird_notice'],\n",
      "      dtype='object')\n",
      "After encoding: (3321201, 96)\n",
      "Columns after encoding categorical variables:\n",
      " Index(['proto', 'seq', 'stddev', 'N_IN_Conn_P_SrcIP', 'min', 'state_number',\n",
      "       'mean', 'N_IN_Conn_P_DstIP', 'drate', 'srate', 'max', 'label', 'type',\n",
      "       'subcategory', 'id', 'dur', 'service', 'state', 'spkts', 'dpkts',\n",
      "       'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss',\n",
      "       'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb',\n",
      "       'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'src_ip', 'src_port', 'dst_ip',\n",
      "       'dst_port', 'duration', 'src_bytes', 'dst_bytes', 'conn_state',\n",
      "       'missed_bytes', 'src_pkts', 'src_ip_bytes', 'dst_pkts', 'dst_ip_bytes',\n",
      "       'dns_query', 'dns_qclass', 'dns_qtype', 'dns_rcode', 'dns_AA', 'dns_RD',\n",
      "       'dns_RA', 'dns_rejected', 'ssl_version', 'ssl_cipher', 'ssl_resumed',\n",
      "       'ssl_established', 'ssl_subject', 'ssl_issuer', 'http_trans_depth',\n",
      "       'http_method', 'http_uri', 'http_version', 'http_request_body_len',\n",
      "       'http_response_body_len', 'http_status_code', 'http_user_agent',\n",
      "       'http_orig_mime_types', 'http_resp_mime_types', 'weird_name',\n",
      "       'weird_addl', 'weird_notice'],\n",
      "      dtype='object')\n",
      "Target column values:\n",
      " label\n",
      "1    3214831\n",
      "0     106370\n",
      "Name: count, dtype: int64\n",
      "Feature columns:\n",
      " Index(['N_IN_Conn_P_DstIP', 'N_IN_Conn_P_SrcIP', 'ackdat', 'conn_state',\n",
      "       'ct_dst_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'ct_flw_http_mthd',\n",
      "       'ct_ftp_cmd', 'ct_src_dport_ltm', 'ct_src_ltm', 'ct_srv_dst',\n",
      "       'ct_srv_src', 'ct_state_ttl', 'dbytes', 'dinpkt', 'djit', 'dload',\n",
      "       'dloss', 'dmean', 'dns_AA', 'dns_RA', 'dns_RD', 'dns_qclass',\n",
      "       'dns_qtype', 'dns_query', 'dns_rcode', 'dns_rejected', 'dpkts', 'drate',\n",
      "       'dst_bytes', 'dst_ip', 'dst_ip_bytes', 'dst_pkts', 'dst_port', 'dtcpb',\n",
      "       'dttl', 'dur', 'duration', 'dwin', 'http_method',\n",
      "       'http_orig_mime_types', 'http_request_body_len', 'http_resp_mime_types',\n",
      "       'http_response_body_len', 'http_status_code', 'http_trans_depth',\n",
      "       'http_uri', 'http_user_agent', 'http_version', 'id', 'is_ftp_login',\n",
      "       'is_sm_ips_ports', 'max', 'mean', 'min', 'missed_bytes', 'proto',\n",
      "       'rate', 'response_body_len', 'sbytes', 'seq', 'service', 'sinpkt',\n",
      "       'sjit', 'sload', 'sloss', 'smean', 'spkts', 'srate', 'src_bytes',\n",
      "       'src_ip', 'src_ip_bytes', 'src_pkts', 'src_port', 'ssl_cipher',\n",
      "       'ssl_established', 'ssl_issuer', 'ssl_resumed', 'ssl_subject',\n",
      "       'ssl_version', 'state', 'state_number', 'stcpb', 'stddev', 'sttl',\n",
      "       'subcategory', 'swin', 'synack', 'tcprtt', 'trans_depth', 'type',\n",
      "       'weird_addl', 'weird_name', 'weird_notice'],\n",
      "      dtype='object')\n",
      "Target column:\n",
      " label\n",
      "Shape of X: (3321201, 95)\n",
      "Shape of y: (3321201,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv(\"/Users/sarahsteadham/Downloads/CyberProject/UNSW2018IOTBOTNET.csv\")\n",
    "df2 = pd.read_csv(\"/Users/sarahsteadham/Downloads/CyberProject/UNSWNB15.csv\")\n",
    "df3 = pd.read_csv(\"/Users/sarahsteadham/Downloads/CyberProject/train_test_network.csv\")\n",
    "\n",
    "# Standardize column names\n",
    "df1.rename(columns={'attack': 'label', 'category': 'type'}, inplace=True)\n",
    "df2.rename(columns={'attack_cat': 'type', 'label': 'label'}, inplace=True)\n",
    "df3.rename(columns={'label': 'label', 'type': 'type'}, inplace=True)\n",
    "\n",
    "# Ensure each dataset has the standardized columns\n",
    "print(\"Dataset 1 Columns after renaming:\", df1.columns)\n",
    "print(\"Dataset 2 Columns after renaming:\", df2.columns)\n",
    "print(\"Dataset 3 Columns after renaming:\", df3.columns)\n",
    "\n",
    "# Inspect target column in each dataset\n",
    "print(\"Dataset 1 'label' column values:\\n\", df1['label'].value_counts())\n",
    "print(\"Dataset 2 'label' column values:\\n\", df2['label'].value_counts())\n",
    "print(\"Dataset 3 'label' column values:\\n\", df3['label'].value_counts())\n",
    "\n",
    "# Combine datasets\n",
    "df_combined = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Check if the combined DataFrame is empty\n",
    "if df_combined.empty:\n",
    "    raise ValueError(\"The combined DataFrame is empty. Please check the input datasets.\")\n",
    "\n",
    "# Debug: Check if 'label' is in the combined DataFrame and its distribution\n",
    "print(\"Combined DataFrame Columns:\", df_combined.columns)\n",
    "print(\"Combined DataFrame 'label' column values:\\n\", df_combined['label'].value_counts())\n",
    "\n",
    "# Check for unintended dropping of rows\n",
    "print(\"Combined DataFrame shape:\", df_combined.shape)\n",
    "print(\"Number of missing values per column:\\n\", df_combined.isnull().sum())\n",
    "\n",
    "# Ensure 'label' is still numerical\n",
    "print(\"Data types of columns:\\n\", df_combined.dtypes)\n",
    "if df_combined['label'].dtype != 'int64' and df_combined['label'].dtype != 'float64':\n",
    "    df_combined['label'] = df_combined['label'].astype(int)\n",
    "    print(\"Converted 'label' to numerical type.\")\n",
    "\n",
    "# Print the first few rows of the combined DataFrame for inspection\n",
    "print(\"Combined DataFrame Head:\\n\", df_combined.head())\n",
    "\n",
    "# Data Preprocessing\n",
    "# Drop any irrelevant columns (if any)\n",
    "df_combined = df_combined.drop(columns=['pkSeqID', 'saddr', 'sport', 'daddr', 'dport'], errors='ignore')\n",
    "\n",
    "# Handle missing values\n",
    "# Fill missing values for critical columns with appropriate values (e.g., mean, median)\n",
    "critical_columns = ['label', 'proto', 'service', 'state', 'src_ip', 'dst_ip']\n",
    "for col in critical_columns:\n",
    "    if col in df_combined.columns:\n",
    "        df_combined[col] = df_combined[col].fillna(df_combined[col].mode()[0])\n",
    "\n",
    "# Drop rows with remaining missing target values\n",
    "df_combined = df_combined.dropna(subset=['label'])\n",
    "\n",
    "# Print the columns after handling missing values\n",
    "print(\"Columns after handling missing values:\\n\", df_combined.columns)\n",
    "\n",
    "# Verify categorical encoding process\n",
    "print(\"Before encoding:\", df_combined.shape)\n",
    "categorical_columns = df_combined.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns to encode:\", categorical_columns)\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_combined[col] = le.fit_transform(df_combined[col])\n",
    "\n",
    "print(\"After encoding:\", df_combined.shape)\n",
    "\n",
    "# Print the columns after encoding\n",
    "print(\"Columns after encoding categorical variables:\\n\", df_combined.columns)\n",
    "\n",
    "# Feature Selection\n",
    "target_column = 'label'\n",
    "\n",
    "# Check if the target column exists in the combined DataFrame\n",
    "if target_column not in df_combined.columns:\n",
    "    raise ValueError(\"The target column does not exist in the combined DataFrame.\")\n",
    "\n",
    "# Print the target column values to ensure they are not empty\n",
    "print(\"Target column values:\\n\", df_combined[target_column].value_counts())\n",
    "\n",
    "feature_columns = df_combined.columns.difference([target_column])\n",
    "\n",
    "# Print the feature and target columns\n",
    "print(\"Feature columns:\\n\", feature_columns)\n",
    "print(\"Target column:\\n\", target_column)\n",
    "\n",
    "X = df_combined[feature_columns]\n",
    "y = df_combined[target_column]\n",
    "\n",
    "# Check if X and y are not empty\n",
    "if X.empty or y.empty:\n",
    "    raise ValueError(\"Feature columns (X) or target column (y) are empty. Please check the data preprocessing steps.\")\n",
    "\n",
    "# Print the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model (if needed)\n",
    "joblib.dump(clf, 'network_anomaly_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b0f47-f43c-43a3-9974-21dfb887df5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
